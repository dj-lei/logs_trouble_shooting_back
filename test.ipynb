{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbc2e3a-893f-4652-b085-d5bb4c10dfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import zlib\n",
    "import base64\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import configparser\n",
    "from utils import *\n",
    "from sys import platform\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "# import torch\n",
    "# from tslearn.metrics import dtw, dtw_path\n",
    "# from tslearn.metrics import lcss, lcss_path\n",
    "# from transformers import BertTokenizer, BertModel\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# tokenizer = BertTokenizer.from_pretrained('google/bert_uncased_L-2_H-128_A-2')\n",
    "# model = BertModel.from_pretrained(\"google/bert_uncased_L-2_H-128_A-2\")\n",
    "# model = model.to(device)\n",
    "# device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0253b509-184b-441e-9a6c-08d7d625752e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf = configparser.ConfigParser()\n",
    "cf.read('config/config.cfg')\n",
    "\n",
    "env = 'DEVELOP'\n",
    "if 'win' in platform:\n",
    "    env = 'DEVELOP'\n",
    "elif 'linux' in platform:\n",
    "    env = 'PRODUCT'\n",
    "    \n",
    "class EsCtrl(object):\n",
    "    def __init__(self):\n",
    "        self.es_ctrl = Elasticsearch(cf['ENV_'+env]['ADDR'], ca_certs=cf['ELASTICSEARCH']['CA_CERTS'])\n",
    "\n",
    "    def query_index_logs(self, index):\n",
    "        # query = {\n",
    "        #     \"match\": {\n",
    "        #         \"trace\": \"com_ericsson_trithread:INFO\"\n",
    "        #     }\n",
    "        # }\n",
    "        #data = self.es_ctrl.search(index=index, query=query, scroll='1s', size=10000)\n",
    "        data = self.es_ctrl.search(index=index, scroll='1s', size=10000)\n",
    "        sid = data['_scroll_id']\n",
    "        scroll_size = len(data['hits']['hits'])\n",
    "        res = []\n",
    "        while scroll_size > 0:\n",
    "            # Before scroll, process current batch of hits\n",
    "            res.extend(data['hits']['hits'])\n",
    "            data = self.es_ctrl.scroll(scroll_id=sid, scroll='1s')\n",
    "            # Update the scroll ID\n",
    "            sid = data['_scroll_id']\n",
    "            # Get the number of results that returned in the last scroll\n",
    "            scroll_size = len(data['hits']['hits'])\n",
    "        return res\n",
    "\n",
    "    def query_indices(self):\n",
    "        res = []\n",
    "        for key in self.es_ctrl.indices.get_alias().keys():\n",
    "            if len(key) > 0:\n",
    "                if '.analyzed_' in key:\n",
    "                    res.append(key.replace('.analyzed_', ''))\n",
    "        return res\n",
    "\n",
    "    def is_exists(self, index):\n",
    "        return self.es_ctrl.indices.exists(index=index)\n",
    "\n",
    "    def count_index(self, index):\n",
    "        return self.es_ctrl.count(index=index)['count']\n",
    "\n",
    "    def store_index(self, index, data):\n",
    "        data = deflate_and_base64_encode(json.dumps(data).encode('utf-8'))\n",
    "        return self.es_ctrl.index(index=index, body={'content': data})\n",
    "\n",
    "    def query_index(self, index):\n",
    "        data = self.es_ctrl.search(index=index)\n",
    "        data = json.loads(decode_base64_and_inflate(data['hits']['hits'][0]['_source']['content']))\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f2c72c-6dd7-4e5f-b00a-861983fc0deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################ Data Clean ################################################\n",
    "def package_kv(df):\n",
    "    res = {}\n",
    "    k_type = {}\n",
    "    for i, (kv,index,timestamp) in enumerate(zip(df.kv.values, df['index'].values, df.timestamp.values)):\n",
    "        for item in kv:\n",
    "            if len(item[1]) > 0:\n",
    "                if item[0] in res:\n",
    "                    res[item[0]].append(item[1]  + [timestamp] + [str(i)] + [index]) # [value1,value2,value3,timestamp,process_index,global_index]\n",
    "                else:\n",
    "                    res[item[0]] = [item[1]  + [timestamp] + [str(i)] + [index]]\n",
    "    for key in res.keys():\n",
    "        width = max(map(len, res[key])) # get max width\n",
    "        type_list = []\n",
    "        for i, item in enumerate(res[key]):\n",
    "            if '0x' in item[0]:\n",
    "                type_list.append('register')\n",
    "            elif item[0].isupper():\n",
    "                type_list.append('discrete')\n",
    "            else:\n",
    "                type_list.append('continuous')\n",
    "                \n",
    "            if len(item) != width:\n",
    "                tmp = [0 for _ in range(0, width)]\n",
    "                tmp[-3] = item[-3]\n",
    "                tmp[-2] = item[-2]\n",
    "                tmp[-1] = item[-1]\n",
    "                res[key][i] = tmp\n",
    "        res[key] = np.array(res[key]).transpose().tolist() # matrix transposition\n",
    "        k_type[key] = 'discrete' if len(set(type_list)) > 1 else list(set(type_list))[0]\n",
    "    return res,k_type\n",
    "\n",
    "\n",
    "def package_inverted_index_table(table, key, data):\n",
    "    def clean_special_symbols(text):\n",
    "        for ch in ['/','*','{','}','[',']','(',')','#','+','-','!','=',':',',','\"']:\n",
    "            if ch in text:\n",
    "                text = text.replace(ch,\" \")\n",
    "        return re.sub(\" +\", \" \", text)\n",
    "    for index, msg in data:\n",
    "        for word in set(clean_special_symbols(msg).split(' ')):\n",
    "            w = word.lower()\n",
    "            if w not in table:\n",
    "                table[w] = {'x': [index], 'y': [key]} # x:global index, y: yaxis num \n",
    "            else:\n",
    "                table[w]['x'].append(index)\n",
    "                table[w]['y'].append(key)\n",
    "\n",
    "\n",
    "def clean_data(esdata):\n",
    "    def clean_msg_special_symbols(text):\n",
    "        for ch in ['{', '}', '[', ']', '(', ')', '\"', '::']:\n",
    "            if ch in text:\n",
    "                text = text.replace(ch, \" \")\n",
    "        return re.sub(\" +\", \" \", text)\n",
    "\n",
    "    story = []\n",
    "    for item in esdata:\n",
    "        if 'msg' in item['_source']:\n",
    "            tmp = clean_msg_special_symbols(item['_source']['msg'])\n",
    "            if len(re.findall('process \\= (.*?)$', tmp)) > 0:\n",
    "                process = re.findall('process \\= (.*?),', tmp)[0]\n",
    "                msg = re.findall('msg \\= (.*?)$', tmp)[0]\n",
    "            #                 fileAndLine = re.findall('fileAndLine \\= \\\"(.*?)\\\"',item['_source']['msg'])[0].split(':')[0]\n",
    "            # elif len(re.findall('procname \\= (.*?)$', tmp)) > 0:\n",
    "            #     process = re.findall('procname \\= (.*?),', tmp)[0]\n",
    "            #     #                 msg = tmp.split(',')[2].replace('\"','').replace('}','').replace('{','')\n",
    "            #     msg = tmp\n",
    "            else:\n",
    "                process = 'main'\n",
    "                msg = tmp\n",
    "                \n",
    "            msg = msg.replace('= ',':').replace(' = ',':').replace(': ',':').replace(' : ',':').replace('=',':')\n",
    "\n",
    "            for elm in re.split('[: ]',msg):\n",
    "                if elm.isupper():\n",
    "                    msg = re.sub('[: ]'+elm, ':'+elm, msg)\n",
    "\n",
    "            msg = re.sub('(:(?!-).*?[ $])', r'\\1,', (msg + ' $'))\n",
    "            # msg\n",
    "            kv = []\n",
    "            for k, v in re.findall('([A-Za-z0-9_.]+?)[ ]?[:=][ ]?(.*?)[,$]', msg):\n",
    "                if len(v.strip()) > 0:\n",
    "                    if (v.strip()+'xx').lower()[0:2] == '0x':\n",
    "                        kv.append((k.strip()+'(r)',  [v.strip()]))\n",
    "                    elif v.strip()[0].isalpha():\n",
    "                        kv.append((k.strip()+'(d)', [v.strip()]))\n",
    "                    else:\n",
    "                        kv.append((k.strip()+'(c)', re.findall('[0-9.]+', v)))\n",
    "                        \n",
    "            millisecond = str(item['_source']['millisecond'])\n",
    "            supply_zero = ''\n",
    "            for _ in range(0, 9-len(millisecond)):\n",
    "                supply_zero = supply_zero + '0'\n",
    "            millisecond = supply_zero + millisecond\n",
    "            story.append([item['_source']['device'], item['_source']['trace'], process,  item['_source']['logtime'][:-1] + '.' + millisecond, item['_source']['msg'], kv])\n",
    "            \n",
    "    story = pd.DataFrame(story, columns=['device', 'trace', 'process', 'timestamp', 'msg', 'kv']).sort_values('timestamp',ascending=True).reset_index(drop=True)\n",
    "\n",
    "    story_line = {}\n",
    "    inverted_index_table = {}\n",
    "    for dev in set(story.device.values):\n",
    "        data = story.loc[(story['device'] == dev), :].reset_index(drop=True)\n",
    "        sub_inverted_index_table = {}\n",
    "        for i, process_name in enumerate(sorted(set(data.process.values), key=list(data.process.values).index)):\n",
    "            process = data.loc[(data['process'] == process_name), :].reset_index()\n",
    "            process['index'] = process['index'].astype(str)\n",
    "            process_start_time = process['timestamp'][0]\n",
    "            process_start_count = process['index'][0]\n",
    "            process_end_time = process['timestamp'][process.shape[0] - 1]\n",
    "            process_end_count = process['index'][process.shape[0] - 1]\n",
    "            package_inverted_index_table(sub_inverted_index_table, i, zip(process['index'].values, process.msg.values))\n",
    "            msg = dict(zip(process['index'].values, [str(a) + '||' + b + '||' + c for a, b, c in\n",
    "                                                     zip(process.index.values, process.timestamp.values,\n",
    "                                                         process.msg.values)]))\n",
    "\n",
    "            kv,k_type = package_kv(process)\n",
    "            if dev not in story_line:\n",
    "                story_line[dev] = [{'process': process_name, 'start_time': process_start_time, 'start_count': process_start_count, 'end_time': process_end_time, 'end_count': process_end_count, 'msg': msg, 'kv': kv}]\n",
    "            else:\n",
    "                story_line[dev].append({'process': process_name, 'start_time': process_start_time, 'start_count': process_start_count, 'end_time': process_end_time, 'end_count': process_end_count, 'msg': msg, 'kv': kv})\n",
    "        inverted_index_table[dev] = sub_inverted_index_table\n",
    "    return {'story_line': story_line, 'inverted_index_table': inverted_index_table}\n",
    "\n",
    "\n",
    "def apply_filter_by_keywords(df):\n",
    "    if (len(set(df['msg']) & set([':', '='])) > 0):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def apply_filter_digit(df):\n",
    "    return re.sub('\\d+', '', df['msg'])\n",
    "\n",
    "\n",
    "def apply_keyword_highlight(df, keywords, color_highlight):\n",
    "    tmp = [item.lower() for item in keywords]\n",
    "    for item in tmp:\n",
    "        if (item == 'abn:') & (item in df['msg'].lower()):\n",
    "            return color_highlight\n",
    "        elif len(set(df['msg'].lower().split(' ')).intersection(set(tmp))) > 0:\n",
    "            return color_highlight\n",
    "    return df['status']\n",
    "\n",
    "\n",
    "def cal_time_difference(start, end):\n",
    "    return datetime.datetime.strptime(end, \"%H:%M:%S\") - datetime.datetime.strptime(start, \"%H:%M:%S\")\n",
    "\n",
    "\n",
    "############################################ XML Compression and Decompression ################################################\n",
    "def decode_base64_and_inflate(b64string):\n",
    "    decoded_data = base64.b64decode(b64string)\n",
    "    return zlib.decompress(decoded_data , -15)\n",
    "\n",
    "\n",
    "def deflate_and_base64_encode(string_val):\n",
    "    zlibbed_str = zlib.compress(string_val)\n",
    "    compressed_string = zlibbed_str[2:-4]\n",
    "    return base64.b64encode(compressed_string).decode(\"utf-8\")\n",
    "\n",
    "############################################ Text ecoder ################################################\n",
    "def pretrained_model_encode_msg(object1, object2):\n",
    "    with torch.no_grad():\n",
    "        object1_inputs = tokenizer(list(object1.msg.values), padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "        object1_outputs = model(**object1_inputs)\n",
    "\n",
    "        object2_inputs = tokenizer(list(object2.msg.values), padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "        object2_outputs = model(**object2_inputs)\n",
    "    return object1_outputs, object2_outputs\n",
    "\n",
    "def onehot_encode_string(str1,str2):\n",
    "    data = []\n",
    "    data.extend(str1)\n",
    "    data.extend(str2)\n",
    "    values = np.array(data)\n",
    "\n",
    "    # integer encode\n",
    "    label_encoder = LabelEncoder().fit(values)\n",
    "    integer_encoded = label_encoder.transform(values)\n",
    "\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    onehot_encoder = OneHotEncoder(sparse=False).fit(integer_encoded)\n",
    "\n",
    "    encoder1 = onehot_encoder.transform(label_encoder.transform(str1).reshape(len(str1), 1))\n",
    "    encoder2 = onehot_encoder.transform(label_encoder.transform(str2).reshape(len(str2), 1))\n",
    "    # inverted = label_encoder.inverse_transform([argmax(onehot_encoded[0, :])])\n",
    "    # print(inverted)\n",
    "    return encoder1,encoder2\n",
    "\n",
    "############################################ Space Vectors Algorithm ################################################\n",
    "def cal_lcss_path_and_score(s_y1, s_y2):\n",
    "    path, score = lcss_path(s_y1, s_y2)\n",
    "    return path, score\n",
    "\n",
    "def cal_dtw_path_and_score(s_y1, s_y2):\n",
    "    path, score = dtw_path(s_y1, s_y2)\n",
    "    return path, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e89550-8aea-4484-85a3-fdc15c89e72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 'exiosuu_glte_malabar_pl_2051_telog_telog_2022-09-30-15-29-19'\n",
    "es_ctrl = EsCtrl()\n",
    "story_data = es_ctrl.query_index_logs(index)\n",
    "data = clean_data(story_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5301e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from extract import *\n",
    "\n",
    "path = 'exiosuu_LTE_TALAGAKOCAK_GH_2052.log'\n",
    "fe = FileExtract(path,'exiosuu_LTE_TALAGAKOCAK_GH_2052.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "provincial-checklist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['BXP_2052_radio6626'])\n"
     ]
    }
   ],
   "source": [
    "if fe.is_extractable:\n",
    "    res = fe.extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3caa8a-fde9-44ca-86f4-e231ebd3d26f",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "# res[0]['origin_logs']['txlProcBranchH'][0:10]\n",
    "# res[0]['kv']['txlProcBranchH']['txAtt(c)']\n",
    "compressed_data = deflate_and_base64_encode(json.dumps(res[0]).encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2afe7250-7976-4c1a-879b-bd4b83ad470d",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from extract import *\n",
    "\n",
    "with open(cf['ENV_'+env]['LOG_STORE_PATH'] + 'ru_lock_unlock_dpd_hw_fault_air6419_mongoose_2022_10_10', \"rb\") as myfile:\n",
    "    S = myfile.read()\n",
    "res = json.loads(gzip.decompress(S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9719b32a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['AntCalGroupMgr', 'AntCalHandler', 'AntCalLogManagerProc', 'BSAas', 'CompensationManagerAas', 'EquipCtrl', 'PaSrv0:1:2:3:4:5:6:7:8:9:10:11:12:13:14:15:16:17:18:19:20:21:22:23:24:25:26:27:28:29:30:31:32:33:34:35:36:37:38:39:40:41:42:43:', 'RxBranchCtrl0', 'RxBranchCtrl1', 'RxBranchCtrl10', 'RxBranchCtrl11', 'RxBranchCtrl12', 'RxBranchCtrl13', 'RxBranchCtrl14', 'RxBranchCtrl15', 'RxBranchCtrl16', 'RxBranchCtrl17', 'RxBranchCtrl18', 'RxBranchCtrl19', 'RxBranchCtrl2', 'RxBranchCtrl20', 'RxBranchCtrl21', 'RxBranchCtrl22', 'RxBranchCtrl23', 'RxBranchCtrl24', 'RxBranchCtrl25', 'RxBranchCtrl26', 'RxBranchCtrl27', 'RxBranchCtrl28', 'RxBranchCtrl29', 'RxBranchCtrl3', 'RxBranchCtrl30', 'RxBranchCtrl31', 'RxBranchCtrl32', 'RxBranchCtrl33', 'RxBranchCtrl34', 'RxBranchCtrl35', 'RxBranchCtrl36', 'RxBranchCtrl37', 'RxBranchCtrl38', 'RxBranchCtrl39', 'RxBranchCtrl4', 'RxBranchCtrl40', 'RxBranchCtrl41', 'RxBranchCtrl42', 'RxBranchCtrl43', 'RxBranchCtrl44', 'RxBranchCtrl45', 'RxBranchCtrl46', 'RxBranchCtrl47', 'RxBranchCtrl48', 'RxBranchCtrl49', 'RxBranchCtrl5', 'RxBranchCtrl50', 'RxBranchCtrl51', 'RxBranchCtrl52', 'RxBranchCtrl53', 'RxBranchCtrl54', 'RxBranchCtrl55', 'RxBranchCtrl56', 'RxBranchCtrl57', 'RxBranchCtrl58', 'RxBranchCtrl59', 'RxBranchCtrl6', 'RxBranchCtrl60', 'RxBranchCtrl61', 'RxBranchCtrl62', 'RxBranchCtrl63', 'RxBranchCtrl7', 'RxBranchCtrl8', 'RxBranchCtrl9', 'TxBranchCtrl0', 'TxBranchCtrl1', 'TxBranchCtrl10', 'TxBranchCtrl11', 'TxBranchCtrl12', 'TxBranchCtrl13', 'TxBranchCtrl14', 'TxBranchCtrl15', 'TxBranchCtrl16', 'TxBranchCtrl17', 'TxBranchCtrl18', 'TxBranchCtrl19', 'TxBranchCtrl2', 'TxBranchCtrl20', 'TxBranchCtrl21', 'TxBranchCtrl22', 'TxBranchCtrl23', 'TxBranchCtrl24', 'TxBranchCtrl25', 'TxBranchCtrl26', 'TxBranchCtrl27', 'TxBranchCtrl28', 'TxBranchCtrl29', 'TxBranchCtrl3', 'TxBranchCtrl30', 'TxBranchCtrl31', 'TxBranchCtrl32', 'TxBranchCtrl33', 'TxBranchCtrl34', 'TxBranchCtrl35', 'TxBranchCtrl36', 'TxBranchCtrl37', 'TxBranchCtrl38', 'TxBranchCtrl39', 'TxBranchCtrl4', 'TxBranchCtrl40', 'TxBranchCtrl41', 'TxBranchCtrl42', 'TxBranchCtrl43', 'TxBranchCtrl44', 'TxBranchCtrl45', 'TxBranchCtrl46', 'TxBranchCtrl47', 'TxBranchCtrl48', 'TxBranchCtrl49', 'TxBranchCtrl5', 'TxBranchCtrl50', 'TxBranchCtrl51', 'TxBranchCtrl52', 'TxBranchCtrl53', 'TxBranchCtrl54', 'TxBranchCtrl55', 'TxBranchCtrl56', 'TxBranchCtrl57', 'TxBranchCtrl58', 'TxBranchCtrl59', 'TxBranchCtrl6', 'TxBranchCtrl60', 'TxBranchCtrl61', 'TxBranchCtrl62', 'TxBranchCtrl63', 'TxBranchCtrl7', 'TxBranchCtrl8', 'TxBranchCtrl9', 'TxRxCoordinationSrv0:1:2:3:4:5:6:7:8:9:10:11:12:13:14:15:16:17:18:19:20:21:22:23:24:25:26:27:28:29:30:31:32:33:34:35:36:37:38:3', 'TxRxLoSrv0:1:2:3:4:5:6:7:8:9:10:11:12:13:14:15:16:17:18:19:20:21:22:23:24:25:26:27:28:29:30:31', 'TxRxLoSrv32:33:34:35:36:37:38:39:40:41:42:43:44:45:46:47:48:49:50:51:52:53:54:55:56:57:58:59:60:61:62:63', 'TxTimingPhaseCtrl0', 'TxTimingPhaseCtrl1', 'TxTimingPhaseCtrl10', 'TxTimingPhaseCtrl11', 'TxTimingPhaseCtrl12', 'TxTimingPhaseCtrl13', 'TxTimingPhaseCtrl14', 'TxTimingPhaseCtrl15', 'TxTimingPhaseCtrl16', 'TxTimingPhaseCtrl17', 'TxTimingPhaseCtrl18', 'TxTimingPhaseCtrl19', 'TxTimingPhaseCtrl2', 'TxTimingPhaseCtrl20', 'TxTimingPhaseCtrl21', 'TxTimingPhaseCtrl22', 'TxTimingPhaseCtrl23', 'TxTimingPhaseCtrl24', 'TxTimingPhaseCtrl25', 'TxTimingPhaseCtrl26', 'TxTimingPhaseCtrl27', 'TxTimingPhaseCtrl28', 'TxTimingPhaseCtrl29', 'TxTimingPhaseCtrl3', 'TxTimingPhaseCtrl30', 'TxTimingPhaseCtrl31', 'TxTimingPhaseCtrl32', 'TxTimingPhaseCtrl33', 'TxTimingPhaseCtrl34', 'TxTimingPhaseCtrl35', 'TxTimingPhaseCtrl36', 'TxTimingPhaseCtrl37', 'TxTimingPhaseCtrl38', 'TxTimingPhaseCtrl39', 'TxTimingPhaseCtrl4', 'TxTimingPhaseCtrl40', 'TxTimingPhaseCtrl41', 'TxTimingPhaseCtrl42', 'TxTimingPhaseCtrl43', 'TxTimingPhaseCtrl44', 'TxTimingPhaseCtrl45', 'TxTimingPhaseCtrl46', 'TxTimingPhaseCtrl47', 'TxTimingPhaseCtrl48', 'TxTimingPhaseCtrl49', 'TxTimingPhaseCtrl5', 'TxTimingPhaseCtrl50', 'TxTimingPhaseCtrl51', 'TxTimingPhaseCtrl52', 'TxTimingPhaseCtrl53', 'TxTimingPhaseCtrl54', 'TxTimingPhaseCtrl55', 'TxTimingPhaseCtrl56', 'TxTimingPhaseCtrl57', 'TxTimingPhaseCtrl58', 'TxTimingPhaseCtrl59', 'TxTimingPhaseCtrl6', 'TxTimingPhaseCtrl60', 'TxTimingPhaseCtrl61', 'TxTimingPhaseCtrl62', 'TxTimingPhaseCtrl63', 'TxTimingPhaseCtrl7', 'TxTimingPhaseCtrl8', 'TxTimingPhaseCtrl9', 'WorkerTaskAas', 'antCalCtrlAas_requestProcessor', 'cfhe', 'cmd_proc', 'faultManagerProc', 'hwLogWriteProc', 'lteNrTddSwitchSrvRadon1x0', 'lteNrTddSwitchSrvRadon1x1', 'lteNrTddSwitchSrvRadon1x2', 'lteNrTddSwitchSrvRadon1x3', 'main', 'radioTrDcServer', 'timeOutSrv', 'tmoSchedulerEqp', 'tmoSchedulerTx', 'trDcProc', 'txlProcBranch0', 'txlProcBranch1', 'txlProcBranch10', 'txlProcBranch11', 'txlProcBranch12', 'txlProcBranch13', 'txlProcBranch14', 'txlProcBranch15', 'txlProcBranch16', 'txlProcBranch17', 'txlProcBranch18', 'txlProcBranch19', 'txlProcBranch2', 'txlProcBranch20', 'txlProcBranch21', 'txlProcBranch22', 'txlProcBranch23', 'txlProcBranch24', 'txlProcBranch25', 'txlProcBranch26', 'txlProcBranch27', 'txlProcBranch28', 'txlProcBranch29', 'txlProcBranch3', 'txlProcBranch30', 'txlProcBranch31', 'txlProcBranch32', 'txlProcBranch33', 'txlProcBranch34', 'txlProcBranch35', 'txlProcBranch36', 'txlProcBranch37', 'txlProcBranch38', 'txlProcBranch39', 'txlProcBranch4', 'txlProcBranch40', 'txlProcBranch41', 'txlProcBranch42', 'txlProcBranch43', 'txlProcBranch44', 'txlProcBranch45', 'txlProcBranch46', 'txlProcBranch47', 'txlProcBranch48', 'txlProcBranch49', 'txlProcBranch5', 'txlProcBranch50', 'txlProcBranch51', 'txlProcBranch52', 'txlProcBranch53', 'txlProcBranch54', 'txlProcBranch55', 'txlProcBranch56', 'txlProcBranch57', 'txlProcBranch58', 'txlProcBranch59', 'txlProcBranch6', 'txlProcBranch60', 'txlProcBranch61', 'txlProcBranch62', 'txlProcBranch63', 'txlProcBranch7', 'txlProcBranch8', 'txlProcBranch9'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['origin_logs'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521a6e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['inverted_index_table']['abn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8a0ecd-8513-4eee-b382-718cf750cb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_msg_special_symbols(text):\n",
    "    for ch in ['{', '}', '[', ']', '(', ')', '\"', '::']:\n",
    "        if ch in text:\n",
    "            text = text.replace(ch, \" \")\n",
    "    return re.sub(\" +\", \" \", text)\n",
    "    \n",
    "# msg = 'GaN Boost mode, set to boost mode Pma:-15.88[-41.54 -9.50] dB, DpdPma:-20.09[-20.58 -19.18] dB, Pmb:-15.88, TorPmb:-15.92[-50.88 -9.50] dB, avgTxPma:-18.14 dB, pmDpdIrqStat:0x00000000, pmScaleFactor: 65K'\n",
    "# msg = 'txAtt:145, txAttPeak:0, dpGainLoopEnable:true, dpGainCtrlType:VVA_QPB93, torTemperature:820 (0.1C), torGainBackoff:0 (0.01dB), torGainLin:3.82825(0.01dB), torStepBit:9, cc1Ctrl1=0x00000100 , avgIMpa0:690 [mAmp]'\n",
    "# msg = '[TXL_GAIN] Pma:-inf[-41.54 -9.50] dB, DpdPma:-inf[-inf -inf] dB, Pmb:-inf, TorPmb:-inf[-inf -9.50] dB, avgTxPma:-inf dB, pmDpdIrqStat:0x00000000, pmScaleFactor: 65K'\n",
    "# msg = 'New event= EVENT_DEACTIVATE carrierId= 196908 fbsId= 1 fbsState= DISABLED cycleRequired= YES 110'\n",
    "# msg = 'Event CARRIER_DEACTIVATE for carrierId:778'\n",
    "# msg = 'Set event RX_SETUP_EVENT to time: 250[ms], from 0x13000e3'\n",
    "# msg = 'New event= EVENT_SETUP carrierId= 771 fbsId= 1 fbsState= SETUP cycleRequired= NO 0'\n",
    "# msg = '0-insertion for fbsId=2 event=EVENT_RELEASE '\n",
    "# msg = 'DP trace: 339: 4909172 dllb_radon.c(4780) INFO:7: Status: stat{dpd=0x00808c10 pd{0=0x00808c10, 1=0x00808410} ec=0x000002ff}'\n",
    "msg = 'txAtt:2500, txAttPeak:0, dpGainLoopEnable:true, dpGainCtrlType:DSA_AD_TXFE, torTemperature:670 (0.1C), torGainBackoff:0 (0.01dB), torGainLin:3.61826(0.01dB), torStepBit:10, cc0Ctrl1=0x00000100 , avgIMpa0:2090 [mAmp]'\n",
    "msg = clean_msg_special_symbols(msg)\n",
    "msg = msg.replace('= ',':').replace(' = ',':').replace(': ',':').replace(' : ',':').replace('=',':')\n",
    "\n",
    "for elm in re.split('[: ]',msg):\n",
    "    if elm.isupper():\n",
    "        msg = re.sub('[: ]'+elm, ':'+elm, msg)\n",
    "\n",
    "msg = re.sub('(:(?!-).*?[ $])', r'\\1,', (msg + ' $'))\n",
    "# msg\n",
    "kv = []\n",
    "for k, v in re.findall('([A-Za-z0-9_.]+?)[ ]?[:=][ ]?(.*?)[,$]', msg):\n",
    "    if (v.strip()+'xx').lower()[0:2] == '0x':\n",
    "        kv.append((k.strip()+'(r)',  [v.strip()]))\n",
    "    elif v.strip()[0].isalpha():\n",
    "        kv.append((k.strip()+'(d)', [v.strip()]))\n",
    "    else:\n",
    "        kv.append((k.strip()+'(c)', re.findall('[0-9.]+', v)))\n",
    "kv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informative-complaint",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_msg_special_symbols(text):\n",
    "    for ch in ['{', '}', '[', ']', '(', ')', '\"', '::', '\\'']:\n",
    "        if ch in text:\n",
    "            text = text.replace(ch, \" \")\n",
    "    return re.sub(\" +\", \" \", text)\n",
    "# msg = 'BXP_2051: [Trace log from 2 restarts before]'\n",
    "# msg = 'BXP_2050: [2022-07-14 21:47:47.132] txlProcBranchA dpdController.cc:3069 INFO:txAtt:1812, txAttPeak:0, dpGainLoopEnable:false, dpGainCtrlType:IDLE, torGainLin:2.61517, torStepBit:7, ccCtrl:0x00000100, avgIMpa0:470 [mAmp]'\n",
    "# msg = 'BXP_2051: [2022-07-09 15:53:37.007706415] (+?.?????????) radio6626 com_ericsson_trithread:INFO: { cpu_id = 3 }, { process = \"txlProcBranchE\", fileAndLine = \"dpdController.cc:2112\", msg = \"Power measurement, Pma:-14.35[-41.54 -9.50] dB, DpdPma:-18.25[-19.05 -17.65] dB, Pmb:-14.35, TorPmb:-14.42[-49.35 -9.50] dB, avgTxPma:-13.62 dB, pmDpdIrqStat:0x00008000, pmScaleFactor: 65K\" }'\n",
    "# msg = '[17:46:31.176471339] (+0.000298760) air6419_mongoose com_ericsson_trithread:INFO: { cpu_id = 3 }, { process = \"txlProcBranch5\", fileAndLine = \"delayEstGen3Drv.cc:240\", msg = \"Fractional delay ok. IntegerDelay: 0x0000030c, FracDelay: 0x0000003a, dpdIrqStat: 0x04000080, dpdStat: 0x04000080, txSurveyMaxDpdAddr: 0x00000101, delEstIntFracDelta: 0xffffffff, delEstIntCorr: 0x00000000, delEstFracCorr: 0x00002000\" }'\n",
    "msg = '{ cpu_id = 3 }, { process = \"txlProcBranch5\", fileAndLine = \"delayEstGen3Drv.cc:240\", msg = \"Fractional delay ok. IntegerDelay: 0x0000030c, FracDelay: 0x0000003a, dpdIrqStat: 0x04000080, dpdStat: 0x04000080, txSurveyMaxDpdAddr: 0x00000101, delEstIntFracDelta: 0xffffffff, delEstIntCorr: 0x00000000, delEstFracCorr: 0x00002000\" }'\n",
    "\n",
    "msg = clean_msg_special_symbols(msg)\n",
    "# re.findall('(.*?): \\[(.*?)\\] \\((.*?)\\) (.*?) (.*?): (.*?)$', msg)\n",
    "# re.findall('\\[(.*?)\\] \\((.*?)\\) (.*?) (.*?): (.*?)$', msg)\n",
    "re.findall('process \\= (.*?),.*?msg \\= (.*)$', msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141331db-0229-4e21-b961-689a957ae326",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abc609c-38cc-4060-a1aa-dac52a02dffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "'0x00000100'.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc9ba49-26ea-4724-bd36-28751e6a4ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'VVA_QPb93'.isupper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ba88a2-a5d4-4c35-95a1-9af6f447b0d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
